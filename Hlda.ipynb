{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ql26M0hSP-cd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8rLpua5zQBAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a01a4ab-7483-4da3-e6f5-3d88518ca25b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/Data/\""
      ],
      "metadata": {
        "id": "VzCXrpEFQKlk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_path+\"Data_clean_processed_sample.csv\")"
      ],
      "metadata": {
        "id": "M9N_yQfDQQYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2qQzYBP7QZC3",
        "outputId": "c54e7fab-7cfe-4971-e715-f6b8ef3d468f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 email_id  \\\n",
              "0                     saibi-e\\inbox\\612#1   \n",
              "1  kitchen-l\\_americas\\netco_restart\\28#2   \n",
              "2                 motley-m\\sent_items\\1#1   \n",
              "3          kaminski-v\\all_documents\\577#1   \n",
              "4              quigley-d\\sent_items\\480#1   \n",
              "\n",
              "                                             subject  \\\n",
              "0                     WSCC (Mahave 02) (San Juan 03)   \n",
              "1                                                RE:   \n",
              "2                         SSARR Update Available Now   \n",
              "3        Credit Risk Model Comments - at this point.   \n",
              "4    Confirmation: Risk Management Simulation Mee...   \n",
              "\n",
              "                                               email  \\\n",
              "0  Dear Power Outage Database Customer,\\n\\nAttach...   \n",
              "1  Ryan is waffling.  I talked to him this weeken...   \n",
              "2  <center><LI><a Href=\"http://www.nwrfc.noaa.gov...   \n",
              "3  Hi everyone,\\n\\nI have run the model and, alon...   \n",
              "4     Hi Dutch,     This message is to confirm ou...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  dear power outage database customer attached f...   \n",
              "1  ryan waffling talked weekend said wife want mo...   \n",
              "2       columbia river basin lower snake updated mar   \n",
              "3  everyone run model along contract brief questi...   \n",
              "4  dutch message confirm meeting thursday novembe...   \n",
              "\n",
              "                                          embeddings  \n",
              "0  dear power outage database customer, attached ...  \n",
              "1  ryan waffling. talked weekend said wife want m...  \n",
              "2  columbia river basin lower snake.....updated: mar  \n",
              "3  everyone, run model and, along contract brief ...  \n",
              "4  dutch, message confirm meeting on, thursday, n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac3e269f-78d5-45a2-8de6-7539fc531b39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>email</th>\n",
              "      <th>bow</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saibi-e\\inbox\\612#1</td>\n",
              "      <td>WSCC (Mahave 02) (San Juan 03)</td>\n",
              "      <td>Dear Power Outage Database Customer,\\n\\nAttach...</td>\n",
              "      <td>dear power outage database customer attached f...</td>\n",
              "      <td>dear power outage database customer, attached ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kitchen-l\\_americas\\netco_restart\\28#2</td>\n",
              "      <td>RE:</td>\n",
              "      <td>Ryan is waffling.  I talked to him this weeken...</td>\n",
              "      <td>ryan waffling talked weekend said wife want mo...</td>\n",
              "      <td>ryan waffling. talked weekend said wife want m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>motley-m\\sent_items\\1#1</td>\n",
              "      <td>SSARR Update Available Now</td>\n",
              "      <td>&lt;center&gt;&lt;LI&gt;&lt;a Href=\"http://www.nwrfc.noaa.gov...</td>\n",
              "      <td>columbia river basin lower snake updated mar</td>\n",
              "      <td>columbia river basin lower snake.....updated: mar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kaminski-v\\all_documents\\577#1</td>\n",
              "      <td>Credit Risk Model Comments - at this point.</td>\n",
              "      <td>Hi everyone,\\n\\nI have run the model and, alon...</td>\n",
              "      <td>everyone run model along contract brief questi...</td>\n",
              "      <td>everyone, run model and, along contract brief ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>quigley-d\\sent_items\\480#1</td>\n",
              "      <td>Confirmation: Risk Management Simulation Mee...</td>\n",
              "      <td>Hi Dutch,     This message is to confirm ou...</td>\n",
              "      <td>dutch message confirm meeting thursday novembe...</td>\n",
              "      <td>dutch, message confirm meeting on, thursday, n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac3e269f-78d5-45a2-8de6-7539fc531b39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac3e269f-78d5-45a2-8de6-7539fc531b39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac3e269f-78d5-45a2-8de6-7539fc531b39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install hlda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaxRLCqcQZFN",
        "outputId": "8ecce8a9-23b8-4ec4-d429-d756ee8dc3f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hlda\n",
            "  Downloading hlda-0.3.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hlda) (1.21.6)\n",
            "Installing collected packages: hlda\n",
            "Successfully installed hlda-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tomotopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85OgH3OPdB57",
        "outputId": "06bbc2e4-343b-4a3c-a399-8d5af1ad95af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tomotopy\n",
            "  Downloading tomotopy-0.12.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.5 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tomotopy) (1.21.6)\n",
            "Installing collected packages: tomotopy\n",
            "Successfully installed tomotopy-0.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tomotopy"
      ],
      "metadata": {
        "id": "Ah4wOjZddIk7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tomotopy.utils import Corpus\n",
        "\n",
        "corpus = Corpus()\n",
        "j = 1\n",
        "for i in df['bow']:\n",
        "  corpus.add_doc(i.split(), a_data=j)\n",
        "  j+=1\n",
        "# corpus.add_doc(\"e f g h i\".split(), a_data=2)\n",
        "# corpus.add_doc(\"i j k l m\".split(), a_data=3)"
      ],
      "metadata": {
        "id": "fyM8AZ6aeh3M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = tomotopy.HLDAModel(min_cf=25, min_df=25, rm_top=0, depth=2, alpha=0.1, eta=0.01, gamma=0.1, corpus=corpus, transform=None)"
      ],
      "metadata": {
        "id": "YophMBUOdKpv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num docs:', len(mdl.docs), ', Vocab size:', len(mdl.used_vocabs), ', Num words:', mdl.num_words)"
      ],
      "metadata": {
        "id": "gGBTJec8FxAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6747bc-5b55-4eec-b70d-03a0d4ba9067"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num docs: 20000 , Vocab size: 0 , Num words: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(0, 20000, 100):\n",
        "    mdl.train(70)\n",
        "    mdl.train(30, freeze_topics=True)\n",
        "    print('Iteration: {:05}\\tll per word: {:.5f}\\tNum. of topics: {}'.format(corpus.global_step, corpus.ll_per_word, corpus.live_k))\n",
        "\n",
        "# for _ in range(0, 2000, 10):\n",
        "#     a.train(10, freeze_topics=True)\n",
        "#     print('Iteration: {:05}\\tll per word: {:.5f}\\tNum. of topics: {}'.format(a.global_step, a.ll_per_word, a.live_k))"
      ],
      "metadata": {
        "id": "ADOkfD4BHpbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I haven't tried this code before.\n",
        "test_result_cps, ll = mdl.infer(corpus)\n",
        "for doc in test_result_cps:\n",
        "    print(doc.path, doc.get_words(top_n=10))"
      ],
      "metadata": {
        "id": "1BnDSuab2Afh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another package: HLDA.sampler"
      ],
      "metadata": {
        "id": "BYOUw5L92-Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hlda.sampler import HierarchicalLDA"
      ],
      "metadata": {
        "id": "k2XvaEqaQZHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = []\n",
        "for sent in df['bow']:\n",
        "  vocab+=sent.split()\n",
        "vocab = sorted(set(vocab))"
      ],
      "metadata": {
        "id": "Xmvt3KeUR1I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_index = {}\n",
        "for i, w in enumerate(vocab):\n",
        "    vocab_index[w] = i"
      ],
      "metadata": {
        "id": "3_BHs8ZEQZLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_corpus = []\n",
        "for doc in df['bow']:\n",
        "    doc = doc.split()\n",
        "    new_doc = []\n",
        "    for word in doc:\n",
        "        word_idx = vocab_index[word]\n",
        "        new_doc.append(word_idx)\n",
        "    new_corpus.append(new_doc)"
      ],
      "metadata": {
        "id": "aO1mOBD5SQDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 10       # no of iterations for the sampler\n",
        "alpha = 10.0          # smoothing over level distributions\n",
        "gamma = 1.0           # CRP smoothing parameter; number of imaginary customers at next, as yet unused table\n",
        "eta = 0.1             # smoothing over topic-word distributions\n",
        "num_levels = 3        # the number of levels in the tree\n",
        "display_topics = 3   # the number of iterations between printing a brief summary of the topics so far\n",
        "n_words = 5           # the number of most probable words to print for each topic after model estimation\n",
        "with_weights = False"
      ],
      "metadata": {
        "id": "hxgooH6-SmIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hlda = HierarchicalLDA(new_corpus, vocab, alpha=alpha, gamma=gamma, eta=eta, num_levels=num_levels)\n",
        "hlda.estimate(n_samples, display_topics=display_topics, n_words=n_words, with_weights=with_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uKz-imzSoXR",
        "outputId": "236d5286-7966-4fd8-c4e4-beb0f01e2ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HierarchicalLDA sampling\n",
            "\n",
            "... 3\n",
            "topic=0 level=0 (documents=20000): please, enron, would, know, get, \n",
            "    topic=1 level=1 (documents=6697): enron, please, would, mail, may, \n",
            "        topic=2 level=2 (documents=1627): power, energy, california, said, state, \n",
            "        topic=7 level=2 (documents=47): folder, synchronizing, item, offline, added, \n",
            "        topic=8 level=2 (documents=3405): please, schedule, agreement, know, thanks, \n",
            "        topic=16 level=2 (documents=1092): imagemasker, way, one, urlmasker, new, \n",
            "        topic=21 level=2 (documents=53): epmi, term, total, deal, short, \n",
            "        topic=31 level=2 (documents=231): time, description, imagemasker, central, standard, \n",
            "        topic=43 level=2 (documents=19): schneider, tirrell, tribolet, hate, harry, \n",
            "        topic=47 level=2 (documents=24): cold, plus, alka, seltzer, medicine, \n",
            "        topic=69 level=2 (documents=23): pcbs, equipment, decontamination, surface, solvent, \n",
            "        topic=96 level=2 (documents=23): btu, mag, weinart, wolf, kadakia, \n",
            "        topic=131 level=2 (documents=23): daren, hpln1220, ubsw, megan, fianancial, \n",
            "        topic=143 level=2 (documents=22): rorschach, reagan, kellogg, spear, lagrosta, \n",
            "        topic=176 level=2 (documents=23): sybase, miami, marcus, loews, 11312firmldcall05, \n",
            "        topic=192 level=2 (documents=14): 5fsrch, qcategory, logqid, 7376ac1fdf4c9c47916e549b2134b5c5, aurl, \n",
            "        topic=206 level=2 (documents=21): footnote, snoring, chattering, affair, briefing, \n",
            "        topic=248 level=2 (documents=20): egs, nahou, psecn01v, duluth, reinstall, \n",
            "        topic=272 level=2 (documents=9): westgasx, mhc, pallen, ect, 5mm, \n",
            "        topic=291 level=2 (documents=7): union, tampico, huntsville, taunton, municipal, \n",
            "        topic=308 level=2 (documents=7): maggie, zzz, eview, ewc, ewbank, \n",
            "        topic=315 level=2 (documents=3): zzz, exalink, ewc, ewbank, ewards, \n",
            "        topic=322 level=2 (documents=2): shine, zzz, ewc, ewards, evp, \n",
            "        topic=323 level=2 (documents=1): zzz, exalink, ewc, ewbank, ewards, \n",
            "        topic=325 level=2 (documents=1): broker, zzz, evmwd, ewc, ewbank, \n",
            "    topic=3 level=1 (documents=2957): enron, new, company, energy, gas, \n",
            "        topic=4 level=2 (documents=24): gerson, allison, collusion, allison_b_sher, barbara, \n",
            "        topic=11 level=2 (documents=299): company, enron, million, said, urlmasker, \n",
            "        topic=12 level=2 (documents=2190): deal, gas, please, need, contract, \n",
            "        topic=50 level=2 (documents=26): circle, gil, thx, everyboby, jinsung, \n",
            "        topic=75 level=2 (documents=31): cumulative, reexecute, sooooo, kay, slowing, \n",
            "        topic=86 level=2 (documents=28): koikos, pcx, tired, pic25955, pete, \n",
            "        topic=104 level=2 (documents=24): epc, jeanerette, relates, bah, koepke, \n",
            "        topic=111 level=2 (documents=35): cpuc01, 003_et_al__, appendix_a_to_a_98, absence, ridout, \n",
            "        topic=129 level=2 (documents=24): tested, chet, transformer, aprart, wont, \n",
            "        topic=140 level=2 (documents=27): thank, slicing, ckm, pat, volleyball, \n",
            "        topic=151 level=2 (documents=26): loud, questioning, julia, suggest, ceaexplanationfinal5, \n",
            "        topic=169 level=2 (documents=22): kennel, rt010918, throughout, zoo, debbie, \n",
            "        topic=202 level=2 (documents=27): shipped, rajaram, crushlink, thread, aparna, \n",
            "        topic=219 level=2 (documents=23): watson, phelps, gmt, tbd, looked, \n",
            "        topic=220 level=2 (documents=24): angela, eb3817, ueta, hitting, washingtonpost, \n",
            "        topic=225 level=2 (documents=21): requisition, refer, hatch, thats, damn, \n",
            "        topic=233 level=2 (documents=28): map, compaq, edt, dell, emc, \n",
            "        topic=237 level=2 (documents=16): chahal, stacey, portable, amir, entouch, \n",
            "        topic=261 level=2 (documents=14): cameron, aye, dari, valentis, blanca, \n",
            "        topic=262 level=2 (documents=24): pcx, monitored, wandering, meticulous, night, \n",
            "        topic=281 level=2 (documents=20): inline, avril, contemplated, yur, energyone, \n",
            "        topic=293 level=2 (documents=4): calendar, lends, converting, zzz, evolution, \n",
            "    topic=5 level=1 (documents=2062): imagemasker, urlmasker, com, get, one, \n",
            "        topic=6 level=2 (documents=598): urlmasker, com, click, offer, email, \n",
            "        topic=15 level=2 (documents=610): price, list, member, click, buy, \n",
            "        topic=22 level=2 (documents=197): task, beer, norm, man, people, \n",
            "        topic=27 level=2 (documents=20): x35491, edgar, ignoring, staff, lavorato, \n",
            "        topic=44 level=2 (documents=190): updated, game, week, yard, fantasy, \n",
            "        topic=49 level=2 (documents=21): dpca, chevron, pges, volumemanagement, accounting, \n",
            "        topic=51 level=2 (documents=25): yowman, round, invalidated, shim, confirms, \n",
            "        topic=57 level=2 (documents=14): dnc, zisman, ashamed, hallwood, benton, \n",
            "        topic=62 level=2 (documents=20): greater, laporte, equistar, leite, phllips, \n",
            "        topic=66 level=2 (documents=34): skiing, paintball, promise, drank, jeanette, \n",
            "        topic=77 level=2 (documents=25): bernacik, laguna, norm, pueblo, lucero, \n",
            "        topic=89 level=2 (documents=28): lucas, sharad, asscoiate, dasovich, arun, \n",
            "        topic=90 level=2 (documents=28): pwx, sleeved, 25mws, bid, enron42, \n",
            "        topic=94 level=2 (documents=17): mpg, javelin, bronze, valentine, palo, \n",
            "        topic=103 level=2 (documents=29): kam, lodging, owinfre, spalmer, severson, \n",
            "        topic=107 level=2 (documents=30): showtime, 00pm, 30pm, 15pm, 45pm, \n",
            "        topic=117 level=2 (documents=28): vng, thanks, sparky, binder, corrected, \n",
            "        topic=132 level=2 (documents=20): ngi, curve, curve_cd, book_type_cd, curve_type_cd, \n",
            "        topic=181 level=2 (documents=21): topock, change, outstanding, thought, lynch, \n",
            "        topic=188 level=2 (documents=18): attys, joannie, alatorre, offseason, 4th, \n",
            "        topic=236 level=2 (documents=27): revisit, nomination___, thsx, okey, scottsdale, \n",
            "        topic=240 level=2 (documents=23): spiking, pierre, yep, bailey, shockley, \n",
            "        topic=279 level=2 (documents=15): windowing, 8mo, syrah, eberle, tod, \n",
            "        topic=283 level=2 (documents=12): hpl0714, lynnette, breslau, vikas, sanjay, \n",
            "        topic=289 level=2 (documents=7): ch2m, mgermany, zzz, evo, ewc, \n",
            "        topic=317 level=2 (documents=3): alford, little, restaraunt, defeateduconn, yorkers, \n",
            "        topic=319 level=2 (documents=2): chihuahua, zzz, eview, ewc, ewbank, \n",
            "    topic=9 level=1 (documents=3642): enron, market, would, price, new, \n",
            "        topic=10 level=2 (documents=2834): power, market, enron, would, company, \n",
            "        topic=26 level=2 (documents=317): imagemasker, com, doc, mail, file, \n",
            "        topic=33 level=2 (documents=28): tube, brg, nozzle, tva, mayeux, \n",
            "        topic=37 level=2 (documents=43): report, public, information, filed, texas, \n",
            "        topic=48 level=2 (documents=16): preface, 4_1, lockdown, indemnity, marcos, \n",
            "        topic=61 level=2 (documents=17): upstairs, condo, kerri, garrison, olinde, \n",
            "        topic=64 level=2 (documents=26): commercial, joanne, rozycki, structuring, interviewing, \n",
            "        topic=82 level=2 (documents=22): que, para, por, leiloes, como, \n",
            "        topic=85 level=2 (documents=23): interesting, flipped, apr, y20134, allen, \n",
            "        topic=99 level=2 (documents=17): hee, perverted, aleck, merrill, translates, \n",
            "        topic=110 level=2 (documents=27): eb3891, stacey, shooting, madam, idol, \n",
            "        topic=148 level=2 (documents=27): rt01, modesto, drift, maranzana, rho, \n",
            "        topic=158 level=2 (documents=16): read, sister, kal, brush, slightest, \n",
            "        topic=160 level=2 (documents=19): toyota, bryan_garrett, ban, stephany, avistar, \n",
            "        topic=179 level=2 (documents=27): uaf, mandell, perry, hcad, patio, \n",
            "        topic=190 level=2 (documents=20): breeze, cracking, lying, liking, faq, \n",
            "        topic=213 level=2 (documents=20): misssing, oops, resent, rata, seating, \n",
            "        topic=224 level=2 (documents=17): esteban, buljevich, cource, interviewed, gno, \n",
            "        topic=238 level=2 (documents=29): morin, aparna, michele, rajaram, idel, \n",
            "        topic=245 level=2 (documents=19): wabash, jpg, indefinitely, swag, htm, \n",
            "        topic=251 level=2 (documents=19): pwr, prc, stnw, wst, ckl, \n",
            "        topic=265 level=2 (documents=15): vt6095, vt6094, nut, humor, blonde, \n",
            "        topic=269 level=2 (documents=13): belgium, dumb, disgusted, terrie, stressing, \n",
            "        topic=287 level=2 (documents=11): californian, peerless, troy, commish, fro, \n",
            "        topic=299 level=2 (documents=11): refreshment, hola, homework, 3264b, sever, \n",
            "        topic=305 level=2 (documents=6): moore, january, hog, exaggerated, evmbaers, \n",
            "        topic=314 level=2 (documents=3): kak, hta, exe, indexof, msie, \n",
            "    topic=13 level=1 (documents=393): font, color, imagemasker, serif, helvetica, \n",
            "        topic=14 level=2 (documents=22): gate, picket, payne, pipefitters, oci, \n",
            "        topic=32 level=2 (documents=49): azps, com, fourcorne345, hpl, pnpkaps230, \n",
            "        topic=74 level=2 (documents=21): holli, dziekuje, except, czekiem, italy, \n",
            "        topic=92 level=2 (documents=28): preacher, donkey, bishop, schwartz, nun, \n",
            "        topic=93 level=2 (documents=25): zach, leaving, outfit, schedulet, forever, \n",
            "        topic=113 level=2 (documents=20): lake, kevin, gate, housing, tjae, \n",
            "        topic=116 level=2 (documents=29): fpc, birthday, letter, minute, homco, \n",
            "        topic=153 level=2 (documents=20): dth, sold, conger, sabra, sprayberry, \n",
            "        topic=155 level=2 (documents=21): methuselah, lived, hermanator, invoked, livin, \n",
            "        topic=186 level=2 (documents=25): misha, 30th, sapphire, incumbent, directory, \n",
            "        topic=193 level=2 (documents=36): font, weather, imagemasker, sans, size, \n",
            "        topic=197 level=2 (documents=23): causholli, monika, 5mw, epe1152, mgg, \n",
            "        topic=212 level=2 (documents=23): kuwait, walter, eb32c2, undergrad, burning, \n",
            "        topic=215 level=2 (documents=22): mertz, photocopying, heater, porta, qfs, \n",
            "        topic=258 level=2 (documents=22): pcx, gregoryh, pic14882, 1mmgreen, sanity, \n",
            "        topic=304 level=2 (documents=7): review, redeliveries, mat, alley, evmbaa, \n",
            "    topic=17 level=1 (documents=726): urlmasker, thanks, com, word, request, \n",
            "        topic=18 level=2 (documents=113): available, webster, capacity, mail, record, \n",
            "        topic=23 level=2 (documents=19): proceed, recs, resultant, thought, contained, \n",
            "        topic=52 level=2 (documents=20): monday, settling, enronatd, cdwr, monumentally, \n",
            "        topic=53 level=2 (documents=26): cpa8, carol, cmd8, erick, worth, \n",
            "        topic=54 level=2 (documents=28): mail, doc, medway, hamilton, sithe, \n",
            "        topic=56 level=2 (documents=31): cad, nggj, west, book, cent, \n",
            "        topic=67 level=2 (documents=22): bofa, aron, sir, great, lagrasta, \n",
            "        topic=70 level=2 (documents=22): sent, thats, patrick, course, denver, \n",
            "        topic=81 level=2 (documents=25): interjet, amerexenergy, sep, protest, austin, \n",
            "        topic=91 level=2 (documents=24): feeling, papasitos, respectfully, albrecht, bolded, \n",
            "        topic=105 level=2 (documents=23): bernhard, designated, marlena, steinacher, hitter, \n",
            "        topic=106 level=2 (documents=23): hpln1103, fuck, changed, yesterday, yearend, \n",
            "        topic=115 level=2 (documents=25): ext, isc, reset, botchy, gc010612, \n",
            "        topic=125 level=2 (documents=21): nn5441, susan, lynch, honest, shackleton, \n",
            "        topic=138 level=2 (documents=18): sebesta, diagram, bakanic, efs, okay, \n",
            "        topic=144 level=2 (documents=24): alok, laura, angelica, gullable, leslie, \n",
            "        topic=152 level=2 (documents=34): explorer, gda, prepay, cayanosa, galveston, \n",
            "        topic=161 level=2 (documents=18): lallani, moyez, prefer, sarcastic, emailed, \n",
            "        topic=178 level=2 (documents=11): politician, bloomberg, limiting, scotty, zmcclure, \n",
            "        topic=189 level=2 (documents=20): workshop, wanted, capture, honey, preponderance, \n",
            "        topic=204 level=2 (documents=31): convention, reveal, rounding, decimal, locs, \n",
            "        topic=205 level=2 (documents=17): voodoodick, exe, terrible, funny, gotten, \n",
            "        topic=207 level=2 (documents=15): host, published, val, cellphone, anxiuos, \n",
            "        topic=222 level=2 (documents=22): bridget, lying, awake, reccomendations, xmas, \n",
            "        topic=227 level=2 (documents=21): sarah, jessie, mcconnell, perplexed, midc, \n",
            "        topic=242 level=2 (documents=31): nbr, caspian, bulb, japan, calder, \n",
            "        topic=256 level=2 (documents=15): preparer, bilateral, seelig, fka, seguin, \n",
            "        topic=271 level=2 (documents=11): adn, electric, dropbox, hte, 22nd, \n",
            "        topic=277 level=2 (documents=7): resolution, prerating, forecast, zzz, evmbaa, \n",
            "        topic=300 level=2 (documents=7): showing, bluedolphin, sake, bark, cowtrap, \n",
            "        topic=303 level=2 (documents=2): unsure, message, rhonda, mcandrew, zzz, \n",
            "    topic=19 level=1 (documents=349): fyi, thanks, please, attached, tomas, \n",
            "        topic=20 level=2 (documents=15): jpmorgan, hultman, cagle, indiana, questionairre, \n",
            "        topic=45 level=2 (documents=18): isanderson, personality, quick, 20010919ercot_load, 0b2, \n",
            "        topic=46 level=2 (documents=27): gonna, bmw, jerome, mina, pencil, \n",
            "        topic=71 level=2 (documents=27): barton, compressor, station, brindle, baby, \n",
            "        topic=101 level=2 (documents=23): offpeak, r11, titled, guided, vicky, \n",
            "        topic=108 level=2 (documents=21): badge, tantra, makkai, graduating, para, \n",
            "        topic=122 level=2 (documents=33): pavetto, restaurant, zaremberg, ella, john, \n",
            "        topic=171 level=2 (documents=26): cant, youre, november, kristi, lying, \n",
            "        topic=198 level=2 (documents=24): graph, melinda, gallishaw, instinct, mw10, \n",
            "        topic=209 level=2 (documents=30): usd, colonial, ranadive, epme, honey, \n",
            "        topic=218 level=2 (documents=24): hpln0502, pgas, actual, shit, enrontrevinoplt070800, \n",
            "        topic=246 level=2 (documents=26): pappasito, cord, armstrong, leisurely, adult, \n",
            "        topic=250 level=2 (documents=13): taught, mother, cry, straighten, gurusamy, \n",
            "        topic=259 level=2 (documents=13): hourahead, inconvenience, rtf, luv, 1_amendments, \n",
            "        topic=276 level=2 (documents=8): janette, administrtion, morn, graph, evolution, \n",
            "        topic=282 level=2 (documents=14): arre, suitability, annuity, kwp, hound, \n",
            "        topic=292 level=2 (documents=7): willie, interfaced, went, japan, arbitrate, \n",
            "    topic=24 level=1 (documents=553): thanks, fyi, pending, attached, file, \n",
            "        topic=25 level=2 (documents=26): whaler, sealant, supplier, starbrite, silicone, \n",
            "        topic=30 level=2 (documents=37): telex, bar, hoegh, inmarsat, salad, \n",
            "        topic=34 level=2 (documents=34): lanz, balance, gaona, felicity, pertaining, \n",
            "        topic=38 level=2 (documents=42): teeside, eutee, true, patrick, matthew, \n",
            "        topic=65 level=2 (documents=39): cut, quantity, jpg, working, confirmed, \n",
            "        topic=76 level=2 (documents=41): database, error, dbcaps97data, alias, operation, \n",
            "        topic=98 level=2 (documents=34): upgraded, 9th, meet, went, wednesday, \n",
            "        topic=114 level=2 (documents=30): btu, mdth, wg041601, bow, redlines, \n",
            "        topic=127 level=2 (documents=36): superscript, cee, rbp, navy, movie, \n",
            "        topic=134 level=2 (documents=22): jen, memorial, hang, lia, yeh, \n",
            "        topic=142 level=2 (documents=31): pix, gave, lee, queen, chat, \n",
            "        topic=166 level=2 (documents=20): coh, worldnet, royjshanker, joint, udcs, \n",
            "        topic=170 level=2 (documents=23): onexchange, ref, rgds, druzbik, benef, \n",
            "        topic=203 level=2 (documents=15): sorted, parkhill, 20011225ercot_load, christie, zzz, \n",
            "        topic=210 level=2 (documents=21): hpl0630, fair, trail, broker, bbq, \n",
            "        topic=223 level=2 (documents=31): sitpara, invoicing, 3ac, dealcapture, ava, \n",
            "        topic=244 level=2 (documents=24): cordless, centana, ivins, underwriting, russel, \n",
            "        topic=257 level=2 (documents=14): walc, crspm1, bhpl, pse, znayu, \n",
            "        topic=266 level=2 (documents=16): cabana, nephew, autodesk, morning, jam, \n",
            "        topic=284 level=2 (documents=12): havent, chelan, wade, settlement, evmbaers, \n",
            "        topic=297 level=2 (documents=4): shandy, twanda, zzz, evmbaers, ewards, \n",
            "        topic=301 level=2 (documents=1): zzz, exalink, ewc, ewbank, ewards, \n",
            "    topic=28 level=1 (documents=503): enron, com, bpa, thanks, fyi, \n",
            "        topic=29 level=2 (documents=28): suicide, int6o, avi, joe, lawyer, \n",
            "        topic=42 level=2 (documents=74): enron, com, ect, hou, gov, \n",
            "        topic=97 level=2 (documents=25): ormet, confused, ghostbusters, jen, bjenks1808, \n",
            "        topic=102 level=2 (documents=32): wine, restaurant, spicy, recipe, hts, \n",
            "        topic=126 level=2 (documents=34): displacement, jeanne, validate, specific, surely, \n",
            "        topic=149 level=2 (documents=16): yolanda, predicted, adv, split, epa, \n",
            "        topic=167 level=2 (documents=27): ameren, sansom, fyr, novation, ectric, \n",
            "        topic=183 level=2 (documents=21): lodisco, sec, psa, is785, liquidate, \n",
            "        topic=184 level=2 (documents=23): designee, broad, farmer, geoff, rgds, \n",
            "        topic=194 level=2 (documents=22): assembly, peachridge, leader, costigan, ravi, \n",
            "        topic=201 level=2 (documents=24): unit, pg7121ea, mcf, w501d5a, gtc, \n",
            "        topic=208 level=2 (documents=27): nomlogic, simulation, user, loaner, vandhana, \n",
            "        topic=216 level=2 (documents=24): clara, paint, driscoll, buck, 317970_1, \n",
            "        topic=221 level=2 (documents=20): four, ljk, serc, watch, maughn, \n",
            "        topic=228 level=2 (documents=22): ravi, blvd, disregard, rio, woodland, \n",
            "        topic=247 level=2 (documents=19): bday, decent, soooo, laura, group, \n",
            "        topic=252 level=2 (documents=16): gilligan, map, midland, honeywell, trkl, \n",
            "        topic=270 level=2 (documents=15): 1n2, sure, cabinet, datamanager, useful, \n",
            "        topic=285 level=2 (documents=14): piatek, appt, czas, palo, czy, \n",
            "        topic=302 level=2 (documents=8): jil, highlighted, allocated, heath, patagonia, \n",
            "        topic=306 level=2 (documents=2): zzz, exalink, ewc, ewbank, ewards, \n",
            "        topic=309 level=2 (documents=3): seagull, crsp, ahold, wapa, evmbaers, \n",
            "        topic=312 level=2 (documents=1): zzz, exalink, ewc, ewbank, ewards, \n",
            "        topic=313 level=2 (documents=6): bout, favorite, winery, zzz, evmwd, \n",
            "    topic=35 level=1 (documents=607): com, hotel, please, special, day, \n",
            "        topic=36 level=2 (documents=19): digiacomo, twin, minature, adopts, readable, \n",
            "        topic=39 level=2 (documents=29): loop, day, lizzette, ninfa, enron_doc, \n",
            "        topic=40 level=2 (documents=30): score, insider, achieving, pookie, downloads, \n",
            "        topic=41 level=2 (documents=23): homewrite, definitely, iaia, decides, unoriginal, \n",
            "        topic=55 level=2 (documents=89): sheraton, hotel, rate, day, new, \n",
            "        topic=63 level=2 (documents=17): viawest, allpartycema, congrats, venturatos, frens2, \n",
            "        topic=78 level=2 (documents=24): mahesh, westbrook, sunset, screw, cornell, \n",
            "        topic=79 level=2 (documents=25): mitsui, tulane, consumption, churn, matt, \n",
            "        topic=80 level=2 (documents=21): eliminated, valley, happily, marlow, julian, \n",
            "        topic=109 level=2 (documents=32): tendered, blmfld, eff, caf, erms, \n",
            "        topic=112 level=2 (documents=24): questar, trailblazer, listened, postions, trevor, \n",
            "        topic=145 level=2 (documents=26): rice, edu, invitation, ostdiek, yahoo, \n",
            "        topic=147 level=2 (documents=24): eco, cabot, cargo, winter, replacement, \n",
            "        topic=159 level=2 (documents=25): mariner, enw, zach, yummy, hemisphere, \n",
            "        topic=175 level=2 (documents=23): pcx, oakland, speedy, repaired, schwartzenburg, \n",
            "        topic=177 level=2 (documents=26): fyi, tommorrow, sandiego, herbst, singer, \n",
            "        topic=180 level=2 (documents=20): self, template, ewooglin, dorg, loss_cmp_flg, \n",
            "        topic=187 level=2 (documents=24): agilon, bmo, galant, forget, nda, \n",
            "        topic=232 level=2 (documents=20): feb, patty, rodeo, del, concert, \n",
            "        topic=234 level=2 (documents=26): katie, trullinger, originated, hiring, rubena, \n",
            "        topic=241 level=2 (documents=22): copier, szabo, 19k1, inch, minolta, \n",
            "        topic=260 level=2 (documents=23): avails_jul, cantekin, vgs, rolodex, fletch, \n",
            "        topic=268 level=2 (documents=10): handheld, impressive, landing, elf, pawlowski, \n",
            "        topic=294 level=2 (documents=5): qte, tan, virgo, telecon, helen, \n",
            "    topic=58 level=1 (documents=641): thanks, fyi, think, doc, upgraded, \n",
            "        topic=59 level=2 (documents=27): granted, beneficiary, granting, vested, validity, \n",
            "        topic=60 level=2 (documents=22): sch, hollis, liking, elp, benjamin, \n",
            "        topic=68 level=2 (documents=25): rfr, gerald, realizing, snilec05, swell, \n",
            "        topic=72 level=2 (documents=20): serviced, happening, 37c1, male, liar, \n",
            "        topic=73 level=2 (documents=19): wbradford, coulter, evaluate, flood, everytime, \n",
            "        topic=83 level=2 (documents=22): mikie, evelyn, westwing, organizer, cube, \n",
            "        topic=84 level=2 (documents=28): cam, flexibility, pleasure, 1_28_02lo, guz, \n",
            "        topic=95 level=2 (documents=34): resid, schenck, rolling, abandonment, chicken, \n",
            "        topic=100 level=2 (documents=21): buy, downgraded, coverage, strong, initiated, \n",
            "        topic=135 level=2 (documents=30): gasket, bradley, pst, restored, emailed, \n",
            "        topic=136 level=2 (documents=36): viagra, generic, sildenafil, pepsi, citrate, \n",
            "        topic=139 level=2 (documents=25): tonight, separator, carta, eesi, tks, \n",
            "        topic=150 level=2 (documents=27): pig, station, smart, agm, mainline, \n",
            "        topic=162 level=2 (documents=27): wee, college, fraternity, wiht, leaving, \n",
            "        topic=164 level=2 (documents=18): pop, doer, draft2, eplf, microwave, \n",
            "        topic=165 level=2 (documents=33): method, wide, dennis, sandy, dbl, \n",
            "        topic=168 level=2 (documents=17): stacey, horowitz, gcp, quitting, tel, \n",
            "        topic=173 level=2 (documents=22): yep, sci, earthlink, pennisi, lqcolombo, \n",
            "        topic=182 level=2 (documents=22): inline, ditching, presidency, submittal, dasr, \n",
            "        topic=191 level=2 (documents=28): fax, opt, napishu, cancelled, ross, \n",
            "        topic=196 level=2 (documents=27): mov, grammar, amortize, heck, bonus, \n",
            "        topic=200 level=2 (documents=22): raffle, astros, laptop, kovalcik, pierce, \n",
            "        topic=254 level=2 (documents=20): carol, 6th, janie, plus, shireman, \n",
            "        topic=255 level=2 (documents=22): aspect, men, person, elliott, loi, \n",
            "        topic=264 level=2 (documents=17): trucking, show, coral, sign, art, \n",
            "        topic=273 level=2 (documents=9): dennis, pick, deepa, mallik, zzz, \n",
            "        topic=280 level=2 (documents=13): reclaimed, roseville, attny, terminating, lance, \n",
            "        topic=295 level=2 (documents=5): lauren, video, zzz, ewc, ewards, \n",
            "        topic=307 level=2 (documents=3): zzz, exalink, ewc, ewbank, ewards, \n",
            "    topic=87 level=1 (documents=335): fyi, fourteenth, sie, law, yes, \n",
            "        topic=88 level=2 (documents=35): aiesec, nam, roku, polska, glownej, \n",
            "        topic=118 level=2 (documents=21): authorization, tozzini, spoken, egroups, houdini, \n",
            "        topic=121 level=2 (documents=24): flying, xoxox, premium, amount, emmanuelle, \n",
            "        topic=123 level=2 (documents=26): ever, tardiness, patterson, downsizing, avista, \n",
            "        topic=130 level=2 (documents=25): hplc, viagra, phentrimine, forest, joanie, \n",
            "        topic=133 level=2 (documents=29): court, appeal, justice, supreme, vote, \n",
            "        topic=137 level=2 (documents=20): vpp, stacey, bored, remember, hounding, \n",
            "        topic=146 level=2 (documents=25): regime, tpa, gillaspie, tennis, termed, \n",
            "        topic=154 level=2 (documents=33): grand, blackline, charge, stephanie, hopkins, \n",
            "        topic=163 level=2 (documents=31): winery, hennessy, sonia, central, instrumental, \n",
            "        topic=235 level=2 (documents=20): deficiency_pricing_052201, herndon, burke, park, ebay, \n",
            "        topic=253 level=2 (documents=25): lexis, williamson, seal, postcard, custome, \n",
            "        topic=275 level=2 (documents=6): calender, dub, eb13c2, jealous, evmwd, \n",
            "        topic=286 level=2 (documents=6): kicked, captured, zzz, evmbaers, ewards, \n",
            "        topic=296 level=2 (documents=7): batch, eater, vegetarian, harvey, alan, \n",
            "        topic=316 level=2 (documents=1): lucky, zzz, evo, ewd, ewc, \n",
            "        topic=318 level=2 (documents=1): football, zzz, evmbaa, ewbank, ewards, \n",
            "    topic=119 level=1 (documents=291): thanks, fyi, attached, info, sorry, \n",
            "        topic=120 level=2 (documents=32): vin, que, plus, est, buveurs, \n",
            "        topic=124 level=2 (documents=17): workspace, historicals, basin, aloe, placing, \n",
            "        topic=128 level=2 (documents=19): ohhh, banking, malme, eric_gordon, quit, \n",
            "        topic=141 level=2 (documents=28): 00008b, cushion, leaseco, aufklaerung, banc, \n",
            "        topic=172 level=2 (documents=28): pgtt, altrade, upstream, scary, ina, \n",
            "        topic=185 level=2 (documents=22): ravi, doesnt, thuraisingham, lunz, cfa, \n",
            "        topic=199 level=2 (documents=21): bates, care, vague, rebooked, address, \n",
            "        topic=214 level=2 (documents=28): nom, hpl, recommending, omnipath, delta, \n",
            "        topic=217 level=2 (documents=14): dirty, mabanaft, sell, nicholls, herstadt, \n",
            "        topic=231 level=2 (documents=17): slept, gmt, linhart, entire, seen, \n",
            "        topic=249 level=2 (documents=28): matt, palmer, account, hiring, flooding, \n",
            "        topic=263 level=2 (documents=12): demonstrate, stubborness, wanna, combustion, spoke, \n",
            "        topic=288 level=2 (documents=11): cannnot, simpler, withholding, skiing, haig, \n",
            "        topic=290 level=2 (documents=12): bnaweb22, lemore, horton, sonya, lucky, \n",
            "        topic=311 level=2 (documents=2): zzz, exalink, ewc, ewbank, ewards, \n",
            "    topic=156 level=1 (documents=170): doc, show, fyi, see, internet, \n",
            "        topic=157 level=2 (documents=20): qb2221, q81652, found, aron, survivor, \n",
            "        topic=174 level=2 (documents=21): surgery, cob, lasik, guess, adm81300, \n",
            "        topic=195 level=2 (documents=29): bushton, transcript, karl, boiler, pedron, \n",
            "        topic=211 level=2 (documents=26): linden, jedi, cogen, camden, att1, \n",
            "        topic=226 level=2 (documents=20): brad, room, elk, af3, nemec, \n",
            "        topic=239 level=2 (documents=27): seb, barrier, residency, radio, dance, \n",
            "        topic=267 level=2 (documents=20): cha, monk, cafe, shank, skilling, \n",
            "        topic=310 level=2 (documents=3): lied, zzz, evo, ewd, ewc, \n",
            "        topic=320 level=2 (documents=2): jgm, zzz, eview, ewc, ewbank, \n",
            "        topic=321 level=2 (documents=1): zzz, exalink, ewc, ewbank, ewards, \n",
            "        topic=324 level=2 (documents=1): tab, spreadsheet, zzz, evmbaers, ewbank, \n",
            "    topic=229 level=1 (documents=74): fyi, sprayed, cdst, league, clair, \n",
            "        topic=230 level=2 (documents=20): 128mb, laughed, fancy, eb2644k, ecth, \n",
            "        topic=243 level=2 (documents=20): footnote, q71102, cdt, reversal, gngr, \n",
            "        topic=274 level=2 (documents=9): song, funny, quesyions, trina, carol, \n",
            "        topic=278 level=2 (documents=16): osman, wessels, litigation, perimeter, modification, \n",
            "        topic=298 level=2 (documents=9): 82214_v7, pacificorp, rives, routkast, zzz, \n",
            ".."
          ]
        }
      ]
    }
  ]
}