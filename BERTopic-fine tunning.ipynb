{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c64b2ae",
   "metadata": {},
   "source": [
    "# BERTopic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf848c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\p_uli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\p_uli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\p_uli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "import tensorflow as tf\n",
    "# from cuml.cluster import HDBSCAN\n",
    "# from cuml.manifold import UMAP\n",
    "# from cuml.preprocessing import normalize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup   \n",
    "import contractions,unicodedata\n",
    "\n",
    "\n",
    "nltk.download('stopwords')                              # Download Stopwords.\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer                     # Stemmer\n",
    "from nltk.corpus import stopwords                       # Import stopwords.\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer         # Import Lemmatizer.\n",
    "\n",
    "\n",
    "import spacy\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16eace90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r'C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Data\\mask_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ee5d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email_id</th>\n",
       "      <th>email</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p\\all_documents\\100#2</td>\n",
       "      <td>PERSON , \\r\\n\\r\\n Please use the second check ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p\\all_documents\\101#2</td>\n",
       "      <td>STRUCTURE : \\r\\n Typically the structure is a ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p\\all_documents\\103#1</td>\n",
       "      <td>---------------------- Forwarded by PERSON on ...</td>\n",
       "      <td>Re : 2001 Margin Plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p\\all_documents\\104#1</td>\n",
       "      <td>Internet Data Gain Is a Major Power Drain on \\...</td>\n",
       "      <td>Var, Reporting and Resources Meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>allen-p\\all_documents\\105#1</td>\n",
       "      <td>Do not underestimate the effects of the Intern...</td>\n",
       "      <td>Westgate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     email_id  \\\n",
       "0           0  allen-p\\all_documents\\100#2   \n",
       "1           1  allen-p\\all_documents\\101#2   \n",
       "2           3  allen-p\\all_documents\\103#1   \n",
       "3           4  allen-p\\all_documents\\104#1   \n",
       "4           5  allen-p\\all_documents\\105#1   \n",
       "\n",
       "                                               email  \\\n",
       "0  PERSON , \\r\\n\\r\\n Please use the second check ...   \n",
       "1  STRUCTURE : \\r\\n Typically the structure is a ...   \n",
       "2  ---------------------- Forwarded by PERSON on ...   \n",
       "3  Internet Data Gain Is a Major Power Drain on \\...   \n",
       "4  Do not underestimate the effects of the Intern...   \n",
       "\n",
       "                                          subject  \n",
       "0    Consolidated positions : Issues & To Do list  \n",
       "1    Consolidated positions : Issues & To Do list  \n",
       "2                           Re : 2001 Margin Plan  \n",
       "3            Var, Reporting and Resources Meeting  \n",
       "4                                        Westgate  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc7613",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07c7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['email'] = data['email'].str.strip()\n",
    "#data['subject'] = data['subject'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39bd9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utl removal\n",
    "def remove_url(text):\n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(regex, '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "data['clean_text'] = data['email'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a20d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html tag removal\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(lambda x: strip_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6dc1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email_id</th>\n",
       "      <th>email</th>\n",
       "      <th>subject</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p\\all_documents\\100#2</td>\n",
       "      <td>PERSON , \\r\\n\\r\\n Please use the second check ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>PERSON , \\r\\n\\r\\n Please use the second check ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p\\all_documents\\101#2</td>\n",
       "      <td>STRUCTURE : \\r\\n Typically the structure is a ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>STRUCTURE : \\r\\n Typically the structure is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p\\all_documents\\103#1</td>\n",
       "      <td>---------------------- Forwarded by PERSON on ...</td>\n",
       "      <td>Re : 2001 Margin Plan</td>\n",
       "      <td>---------------------- Forwarded by PERSON on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p\\all_documents\\104#1</td>\n",
       "      <td>Internet Data Gain Is a Major Power Drain on \\...</td>\n",
       "      <td>Var, Reporting and Resources Meeting</td>\n",
       "      <td>Internet Data Gain Is a Major Power Drain on \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>allen-p\\all_documents\\105#1</td>\n",
       "      <td>Do not underestimate the effects of the Intern...</td>\n",
       "      <td>Westgate</td>\n",
       "      <td>Do not underestimate the effects of the Intern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     email_id  \\\n",
       "0           0  allen-p\\all_documents\\100#2   \n",
       "1           1  allen-p\\all_documents\\101#2   \n",
       "2           3  allen-p\\all_documents\\103#1   \n",
       "3           4  allen-p\\all_documents\\104#1   \n",
       "4           5  allen-p\\all_documents\\105#1   \n",
       "\n",
       "                                               email  \\\n",
       "0  PERSON , \\r\\n\\r\\n Please use the second check ...   \n",
       "1  STRUCTURE : \\r\\n Typically the structure is a ...   \n",
       "2  ---------------------- Forwarded by PERSON on ...   \n",
       "3  Internet Data Gain Is a Major Power Drain on \\...   \n",
       "4  Do not underestimate the effects of the Intern...   \n",
       "\n",
       "                                          subject  \\\n",
       "0    Consolidated positions : Issues & To Do list   \n",
       "1    Consolidated positions : Issues & To Do list   \n",
       "2                           Re : 2001 Margin Plan   \n",
       "3            Var, Reporting and Resources Meeting   \n",
       "4                                        Westgate   \n",
       "\n",
       "                                          clean_text  \n",
       "0  PERSON , \\r\\n\\r\\n Please use the second check ...  \n",
       "1  STRUCTURE : \\r\\n Typically the structure is a ...  \n",
       "2  ---------------------- Forwarded by PERSON on ...  \n",
       "3  Internet Data Gain Is a Major Power Drain on \\...  \n",
       "4  Do not underestimate the effects of the Intern...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contractions removal\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(lambda x: replace_contractions(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33219341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing numbers\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(lambda x: remove_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7241ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "data['clean_text'] = data.apply(lambda row: nltk.word_tokenize(row['clean_text']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7af7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.4 s\n",
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email_id</th>\n",
       "      <th>email</th>\n",
       "      <th>subject</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p\\all_documents\\100#2</td>\n",
       "      <td>PERSON , \\r\\n\\r\\n Please use the second check ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>person please use second check october payment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p\\all_documents\\101#2</td>\n",
       "      <td>STRUCTURE : \\r\\n Typically the structure is a ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>structure typically structure limit partnershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p\\all_documents\\103#1</td>\n",
       "      <td>---------------------- Forwarded by PERSON on ...</td>\n",
       "      <td>Re : 2001 Margin Plan</td>\n",
       "      <td>forward person pm invitation chairperson perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p\\all_documents\\104#1</td>\n",
       "      <td>Internet Data Gain Is a Major Power Drain on \\...</td>\n",
       "      <td>Var, Reporting and Resources Meeting</td>\n",
       "      <td>internet data gain major power drain local uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>allen-p\\all_documents\\105#1</td>\n",
       "      <td>Do not underestimate the effects of the Intern...</td>\n",
       "      <td>Westgate</td>\n",
       "      <td>underestimate effect internet economy load gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     email_id  \\\n",
       "0           0  allen-p\\all_documents\\100#2   \n",
       "1           1  allen-p\\all_documents\\101#2   \n",
       "2           3  allen-p\\all_documents\\103#1   \n",
       "3           4  allen-p\\all_documents\\104#1   \n",
       "4           5  allen-p\\all_documents\\105#1   \n",
       "\n",
       "                                               email  \\\n",
       "0  PERSON , \\r\\n\\r\\n Please use the second check ...   \n",
       "1  STRUCTURE : \\r\\n Typically the structure is a ...   \n",
       "2  ---------------------- Forwarded by PERSON on ...   \n",
       "3  Internet Data Gain Is a Major Power Drain on \\...   \n",
       "4  Do not underestimate the effects of the Intern...   \n",
       "\n",
       "                                          subject  \\\n",
       "0    Consolidated positions : Issues & To Do list   \n",
       "1    Consolidated positions : Issues & To Do list   \n",
       "2                           Re : 2001 Margin Plan   \n",
       "3            Var, Reporting and Resources Meeting   \n",
       "4                                        Westgate   \n",
       "\n",
       "                                          clean_text  \n",
       "0  person please use second check october payment...  \n",
       "1  structure typically structure limit partnershi...  \n",
       "2  forward person pm invitation chairperson perso...  \n",
       "3  internet data gain major power drain local uti...  \n",
       "4  underestimate effect internet economy load gro...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return new_words\n",
    "\n",
    "# def mask_names(words):\n",
    "#     new_words = []\n",
    "#     for word in words:\n",
    "#         doc=nlp(word)\n",
    "#         if doc[0].ent_type_=='PERSON':\n",
    "#             new_words.append('PERSON')\n",
    "#         else:\n",
    "#             new_words.append(word)\n",
    "#     return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_list(words)\n",
    "#     words = mask_names(words)\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['clean_text'] = data.apply(lambda row: normalize(row['clean_text']), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "63f93d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs\n",
    "data.dropna(subset=['clean_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256c7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_trf')\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "\n",
    "def get_ner(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(['PERSON' if t.ent_type_ and t.ent_type_ == 'PERSON' else t.text for t in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d37276a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(r'C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Data\\mask_name_cleaned.csv',index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86757476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>email_id</th>\n",
       "      <th>email</th>\n",
       "      <th>subject</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>allen-p\\all_documents\\100#2</td>\n",
       "      <td>PERSON , \\r\\n\\r\\n Please use the second check ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>person please use second check october payment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>allen-p\\all_documents\\101#2</td>\n",
       "      <td>STRUCTURE : \\r\\n Typically the structure is a ...</td>\n",
       "      <td>Consolidated positions : Issues &amp; To Do list</td>\n",
       "      <td>structure typically structure limit partnershi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>allen-p\\all_documents\\103#1</td>\n",
       "      <td>---------------------- Forwarded by PERSON on ...</td>\n",
       "      <td>Re : 2001 Margin Plan</td>\n",
       "      <td>forward person pm invitation chairperson perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>allen-p\\all_documents\\104#1</td>\n",
       "      <td>Internet Data Gain Is a Major Power Drain on \\...</td>\n",
       "      <td>Var, Reporting and Resources Meeting</td>\n",
       "      <td>internet data gain major power drain local uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>allen-p\\all_documents\\105#1</td>\n",
       "      <td>Do not underestimate the effects of the Intern...</td>\n",
       "      <td>Westgate</td>\n",
       "      <td>underestimate effect internet economy load gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     email_id  \\\n",
       "0           0  allen-p\\all_documents\\100#2   \n",
       "1           1  allen-p\\all_documents\\101#2   \n",
       "2           3  allen-p\\all_documents\\103#1   \n",
       "3           4  allen-p\\all_documents\\104#1   \n",
       "4           5  allen-p\\all_documents\\105#1   \n",
       "\n",
       "                                               email  \\\n",
       "0  PERSON , \\r\\n\\r\\n Please use the second check ...   \n",
       "1  STRUCTURE : \\r\\n Typically the structure is a ...   \n",
       "2  ---------------------- Forwarded by PERSON on ...   \n",
       "3  Internet Data Gain Is a Major Power Drain on \\...   \n",
       "4  Do not underestimate the effects of the Intern...   \n",
       "\n",
       "                                          subject  \\\n",
       "0    Consolidated positions : Issues & To Do list   \n",
       "1    Consolidated positions : Issues & To Do list   \n",
       "2                           Re : 2001 Margin Plan   \n",
       "3            Var, Reporting and Resources Meeting   \n",
       "4                                        Westgate   \n",
       "\n",
       "                                          clean_text  \n",
       "0  person please use second check october payment...  \n",
       "1  structure typically structure limit partnershi...  \n",
       "2  forward person pm invitation chairperson perso...  \n",
       "3  internet data gain major power drain local uti...  \n",
       "4  underestimate effect internet economy load gro...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(r'C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Data\\mask_name_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd88549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2= data.sample(n=20000)\n",
    "if type(data['clean_text']) is list:\n",
    "    text = data['clean_text']\n",
    "else:\n",
    "    text = data['clean_text'].tolist()\n",
    "\n",
    "text=[str(x) for x in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbe87e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ad1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the grid to implement Random Search CV\n",
    "\n",
    "## BERTopic hyperparameters\n",
    "# transformers. Taken from https://www.sbert.net/docs/pretrained_models.html\n",
    "s_transf=['all-MiniLM-L6-v2','all-MiniLM-L12-v2']\n",
    "\n",
    "# top n words per topic, it is recommended to keep this number between 10-20\n",
    "top_n_words=[int(x) for x in np.linspace(10,20,6)]\n",
    "\n",
    "# ngram range: Let's try 1,2 and 3-grams\n",
    "ngram_r=[(1,1),(1,2),(1,3)]\n",
    "\n",
    "# min topic size\n",
    "min_topic_s=[int(x) for x in np.linspace(10,200,6)]\n",
    "\n",
    "## UMAP hyperparameters\n",
    "# number of neighbors\n",
    "n_neigh=[int(x) for x in np.linspace(10,50,6)]\n",
    "\n",
    "## HDBSCAN hyperparameters\n",
    "# min cluster size\n",
    "min_cl_s=[int(x) for x in np.linspace(50,250,6)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bab0c542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015678882598876953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1175,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511f10299a2a4a9c9d6f49f8c267d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 190,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45c8de300d64d399e85b34daf88e469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015549898147583008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 10623,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85cd09bcebf46c5b2e74fd8aff06b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013571977615356445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 573,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22806f0ed4814c898a2622afb98b9c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010007381439208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 116,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534fff8ad30046bfa8ad7d359755ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010929107666015625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 39265,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6041bb68cd7e4cd9b14e1e931c62602f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01492452621459961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 133506609,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59034730e78b491aa5ae855f5c2d7b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015599489212036133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 53,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881d6e477a8a4fb7b874db4d8d5d540e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02051687240600586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 112,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45d4ab524a94f9da224e1c17f4f0e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015546321868896484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466247,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a90a0c08f954e75a054869f72a0cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0012290477752685547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 352,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3523eb35fb1046c28da83adedf707771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015619993209838867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 13159,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c55a82a26d34f7aac82400309133d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015732526779174805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392f76d0f96c4753aad590f90c8a7198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015598535537719727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 349,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a1f1399a774c6eb772d39121a7b062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015623331069946289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 1025,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127e284107094463971c33c6e942a4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 51min 43s\n",
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# with tf.device('/GPU:0'):\n",
    "#     # embedding\n",
    "#     #sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#     sentence_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "#     embeddings = sentence_model.encode(text, show_progress_bar=True)\n",
    "\n",
    "# all_embeddings = np.array(embeddings)\n",
    "# np.save('embeddings_L12.npy', all_embeddings)\n",
    "#embeddings= np.load('embeddings.npy')\n",
    "embeddings= np.load('embeddings_L12.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6467829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(topwords,n_gram,min_top, nn, min_cluster):\n",
    " \n",
    "    # ngrams\n",
    "    vectorizer_model = CountVectorizer(ngram_range=n_gram, stop_words=\"english\")\n",
    "    \n",
    "    # UMAP: dimensionality reduction\n",
    "    umap_model = UMAP(n_neighbors=nn, min_dist=0.0, metric='cosine', random_state=42)\n",
    "    \n",
    "    # HDBSCAN: clustering\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster, metric='euclidean', \n",
    "                            cluster_selection_method='eom', prediction_data=True, min_samples=5)\n",
    "    \n",
    "    cluster_model = KMeans(n_clusters=min_top)\n",
    "    \n",
    "    # BERTopic\n",
    "    model = BERTopic(\n",
    "        top_n_words=topwords,\n",
    "        #min_topic_size=min_top,\n",
    "        nr_topics=min_top,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        language='english', calculate_probabilities=True,\n",
    "        #embedding_model=sentence_model,\n",
    "        verbose=True,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d87fe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x2375c2f0460>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=create_model(20,ngram_r[2],min_topic_s[0],10,min_cl_s[0])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8df3cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 18:50:51,571 - BERTopic - Reduced dimensionality\n",
      "2022-10-24 18:51:22,194 - BERTopic - Clustered reduced embeddings\n",
      "2022-10-24 18:52:03,063 - BERTopic - Reduced number of topics from 138 to 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 46s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/GPU:0'):\n",
    "    topics, probs = model.fit_transform(text,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dbed6ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p_uli\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning:\n",
      "\n",
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "aux=[s_transf[1],20,ngram_r[2],min_topic_s[0],10,min_cl_s[0]]\n",
    "aux=[str(x) for x in aux]\n",
    "model.save(\"_\".join(aux))\n",
    "#model=BERTopic.load(\"_\".join(aux))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b0e101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs=model.probabilities_\n",
    "# topics=model.topics_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af972f19",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8edc69ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>20143</td>\n",
       "      <td>-1_person_enron_company_new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3741</td>\n",
       "      <td>0_person_nt_know_think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1923</td>\n",
       "      <td>1_intend_recipient_person_intend recipient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1407</td>\n",
       "      <td>2_meet_person_pm_person person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>3_energy_person_power_california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>982</td>\n",
       "      <td>4_enron_person_enron north america_enron north</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>965</td>\n",
       "      <td>5_fyi_send_person_fyi fyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>783</td>\n",
       "      <td>6_deal_person_price_volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>676</td>\n",
       "      <td>7_person_agreement_credit_contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>8_thank_person_thank person_person thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>9_final_schedule_hour_variances detect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                            Name\n",
       "0      -1  20143                     -1_person_enron_company_new\n",
       "1       0   3741                          0_person_nt_know_think\n",
       "2       1   1923      1_intend_recipient_person_intend recipient\n",
       "3       2   1407                  2_meet_person_pm_person person\n",
       "4       3   1078                3_energy_person_power_california\n",
       "5       4    982  4_enron_person_enron north america_enron north\n",
       "6       5    965                       5_fyi_send_person_fyi fyi\n",
       "7       6    783                      6_deal_person_price_volume\n",
       "8       7    676              7_person_agreement_credit_contract\n",
       "9       8    588        8_thank_person_thank person_person thank\n",
       "10      9    501          9_final_schedule_hour_variances detect"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = model.get_topic_info()\n",
    "freq.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe195b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create topic assignment per email\n",
    "topics=[]\n",
    "probas=[]\n",
    "for i in range(data.shape[0]):\n",
    "    topics.append(np.argmax(probs[i]))\n",
    "    probas.append(np.max(probs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b02038e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the table with the 20 most important words per topic\n",
    "words=[]\n",
    "c_tfidf=[]\n",
    "top=[]\n",
    "for i in range(0,10):\n",
    "    top= top+ [i]*20\n",
    "    for x in model.get_topic(i): #c-TF-IDF scores\n",
    "        words.append(x[0])\n",
    "        c_tfidf.append(x[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce0cac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "data['topic']=topics\n",
    "data['probs']= probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6ce6d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic words\n",
    "top_words_topic=pd.DataFrame(list(zip(top,words,c_tfidf)),columns=['topic','top_words','c-tf-idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc2ebb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name=[s_transf[0],top_n_words[0],ngram_r[0],min_topic_s[0],10,min_cl_s[0]]\n",
    "file_name=[s_transf[1],20,ngram_r[2],min_topic_s[0],10,min_cl_s[0]]\n",
    "file_name=[str(x) for x in file_name]\n",
    "file_name=\"_\".join(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4b6b0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_topic.to_csv(r'C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Data\\BERTopic\\top_words_{}.csv'.format(file_name),index=False)\n",
    "data.to_csv(r'C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Data\\BERTopic\\assignments_{}.csv'.format(file_name),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7d235",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "46091711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=model.visualize_topics()\n",
    "fig.write_html(r\"C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Images\\BERTopic\\Distance_{}.html\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2e4ddf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy=model.visualize_hierarchy()\n",
    "hierarchy.write_html(r\"C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Images\\BERTopic\\Hierarchy_{}.html\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "beffe842",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_viz=model.visualize_documents(text,embeddings=embeddings)\n",
    "docs_viz.write_html(r\"C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Images\\BERTopic\\Docs_{}.html\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d758e94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bars=model.visualize_barchart(top_n_topics=10)\n",
    "bars.write_html(r\"C:\\Users\\p_uli\\Desktop\\Columbia University\\Cursos\\Fall 22\\Capstone\\Images\\BERTopic\\Bars_{}.html\".format(file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "74890bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Document visualization (left fot the best models)\n",
    "\n",
    "# from umap import UMAP\n",
    "# # Prepare embeddings\n",
    "\n",
    "# sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# embeddings = sentence_model.encode(text, show_progress_bar=False)\n",
    "\n",
    "# # Train BERTopic\n",
    "# topic_model = BERTopic(nr_topics=10,).fit(text, embeddings)\n",
    "\n",
    "# # Run the visualization with the original embeddings\n",
    "# topic_model.visualize_documents(text, embeddings=embeddings)\n",
    "\n",
    "# # Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "# reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "# topic_model.visualize_documents(text, reduced_embeddings=reduced_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce54556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995928b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
